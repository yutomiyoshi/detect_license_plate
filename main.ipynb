{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b379b11-336b-4970-ae89-ba01d5c2e5fb",
   "metadata": {},
   "source": [
    "# 課題1\n",
    "\n",
    "別途支給するテスト用画像(136枚)から、ナンバープレートを検出するプログラムを開発してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa025ad9-73d6-4018-89bb-c58097cf9e80",
   "metadata": {},
   "source": [
    "#### 目標\n",
    "\n",
    "ナンバープレートを検出する学習モデルの生成\n",
    "\n",
    "#### 手順\n",
    "\n",
    "##### 1. 訓練用データを配置する\n",
    "\n",
    "画像(.jpg)とアノテーション(.txt)のデータセットを訓練用(train)と評価用(val)に分割して本ディレクトリに配置する。\n",
    "\n",
    "\n",
    "```\n",
    "datasets\n",
    "├　images\n",
    "│　├　train\n",
    "│　│　└　画像(.jpg)\n",
    "│　└　val\n",
    "│　 　└　YOLO形式(.txt)\n",
    "└　labels\n",
    " 　├　train\n",
    " 　│　└　画像(.jpg)\n",
    " 　└　val\n",
    " 　 　└　YOLO形式(.txt)\n",
    "```\n",
    "\n",
    "##### 2. 訓練する\n",
    "\n",
    "直下セル実行\n",
    "\n",
    "重みファイルがyolov5/runs/train/license_plate_detector/weight/に生成される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b793a1d1-fbed-422c-9dae-2575578d42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python yolov5/train.py --img 640 --batch 16 --epochs 100 --data dataset.yml --weights yolov5/yolov5m.pt --name license_plate_detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8852cf0c-bedf-4061-bb72-4b1da622b457",
   "metadata": {},
   "source": [
    "# 課題2\n",
    "\n",
    "検出したナンバープレートにBounding Boxを描画した画像を出力してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e5cd4e-4c8e-468e-91f9-e23028568d13",
   "metadata": {},
   "source": [
    "#### 目標\n",
    "\n",
    "訓練済みモデルを使用したBounding Boxの推定\n",
    "\n",
    "元画像にBounding Boxを描画\n",
    "\n",
    "#### 手順\n",
    "\n",
    "##### 0. 課題1のコマンドを実行して、モデルを訓練する\n",
    "\n",
    "##### 1. テストデータを配置する\n",
    "\n",
    "Bounding Boxを描画したい画像を配置\n",
    "\n",
    "```\n",
    "tests\n",
    "└　input\n",
    " 　└　画像(.jpg)\n",
    "```\n",
    "\n",
    "##### 2. Bounding Boxを描画する\n",
    "\n",
    "直下セル実行\n",
    "\n",
    "出力先のディレクトリ\n",
    "\n",
    "```\n",
    "tests\n",
    "└　output\n",
    " 　└　画像(.jpg)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb023cb-f2fb-41de-b22b-44d37d884b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 訓練済みモデルのインスタンス化\n",
    "model = torch.hub.load(\n",
    "    \"yolov5\", # モデルを読み込むディレクトリ\n",
    "    \"custom\", # モデルの名前\n",
    "    path=\"yolov5/runs/train/license_plate_detector/weights/best.pt\", # 重みファイルのパス\n",
    "    source=\"local\" # gitの公開モデルではなく、ローカルのモデルを使用する\n",
    ")\n",
    "\n",
    "# 検出しきい値\n",
    "model.conf = 0.5\n",
    "\n",
    "# データアクセス\n",
    "input_img_data_path = \"tests/input\"\n",
    "output_img_data_path = \"tests/output\"\n",
    "\n",
    "# 各画像への処理\n",
    "# Bounding Boxの計算と描画\n",
    "for data_path in glob.glob(\"{0}/*\".format(input_img_data_path)):\n",
    "    file_name = os.path.splitext(os.path.basename(data_path))[0]\n",
    "    img = cv2.imread(data_path)\n",
    "    result = model(img)\n",
    "    for row in result.pandas().xyxy[0].itertuples():\n",
    "        cv2.rectangle(\n",
    "            img, \n",
    "            (math.floor(row.xmin), math.floor(row.ymin)), # Bounding Boxの左上座標\n",
    "            (math.floor(row.xmax), math.floor(row.ymax)), # Bounding Boxの右下座標\n",
    "            color=(255, 255, 0), # 青クリーム色の枠線\n",
    "            thickness=2 # 枠線の太さ\n",
    "        )\n",
    "    cv2.imwrite(\"{0}/{1}.jpg\".format(output_img_data_path, file_name), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1abd9e-a6f4-41d3-a534-b938a9304807",
   "metadata": {},
   "source": [
    "# 課題3\n",
    "\n",
    "黄色のナンバープレート(軽自動車)の件数を出力してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765bf21-77e2-4c5e-b5e8-0c4bd0769fdd",
   "metadata": {},
   "source": [
    "#### 目標\n",
    "\n",
    "訓練モデルを使用したBounding Boxの推定\n",
    "\n",
    "Bouding Box内の代表色を取得\n",
    "\n",
    "ナンバープレートの色の候補からRGBに最も近いものを判定\n",
    "\n",
    "\n",
    "#### 手順\n",
    "\n",
    "##### 0. 課題1のコマンドを実行して、モデルを訓練する\n",
    "\n",
    "##### 1. テストデータを配置する\n",
    "\n",
    "Bounding Boxを描画したい画像を配置\n",
    "\n",
    "```\n",
    "tests\n",
    "└　input\n",
    " 　└　画像(.jpg)\n",
    "```\n",
    "\n",
    "##### 2. 黄色のナンバープレートを数える\n",
    "\n",
    "直下セル実行\n",
    "\n",
    "黄色のナンバープレートの数が出力される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f72d79a-440a-48aa-98a3-a06a98b9cd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'normal', 'path': 'category0.png', 'red': 169.86622807017545, 'blue': 23.91751012145749, 'green': 151.27597840755735}, {'name': 'normal_bussiness', 'path': 'category1.png', 'red': 91.1650641025641, 'blue': 106.20040485829959, 'green': 128.17400472334683}, {'name': 'light', 'path': 'category2.png', 'red': 170.5401484480432, 'blue': 177.6918016194332, 'green': 186.61622807017545}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "category_file = \"license_plate_category/category.json\"\n",
    "\n",
    "with open(category_file, \"r\") as f:\n",
    "    categories = json.load(f)\n",
    "\n",
    "\"\"\"\n",
    "ナンバープレートのカテゴリを判定する\n",
    "\"\"\"\n",
    "def judge_license_plate_category(red, green, blue):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b351a2-49b7-4bf8-8e8c-5456c198c6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 訓練済みモデル\n",
    "model = torch.hub.load(\n",
    "    \"yolov5\", # モデルを読み込むディレクトリ\n",
    "    \"custom\", # モデルの名前\n",
    "    path=\"yolov5/runs/train/license_plate_detector/weights/best.pt\", # 重みファイルのパス\n",
    "    source=\"local\" # gitの公開モデルではなく、ローカルのモデルを使用する\n",
    ")\n",
    "\n",
    "# 検出しきい値\n",
    "model.conf = 0.5\n",
    "\n",
    "# データアクセス\n",
    "input_img_data_path = \"tests/input\"\n",
    "\n",
    "# 各画像への処理とカウンティング\n",
    "total_yello_plate = 0\n",
    "blue_list = []\n",
    "green_list = []\n",
    "red_list = []\n",
    "color_list = []\n",
    "\n",
    "# Bounding Box計算とBox中心のRGB推定\n",
    "for data_path in glob.glob(\"{0}/*\".format(input_img_data_path)):\n",
    "    img = cv2.imread(data_path)\n",
    "    result = model(img) # Bounding Boxの計算\n",
    "    for row in result.pandas().xywh[0].itertuples():\n",
    "        # ナンバープレート幅・高さの半分の領域の平滑色を取得する\n",
    "        x0 = math.floor(row.xcenter - row.width / 2)\n",
    "        y0 = math.floor(row.ycenter - row.height / 2)\n",
    "        x1 = math.floor(row.xcenter + row.width / 2)\n",
    "        y1 = math.floor(row.ycenter + row.height / 2)\n",
    "        extract_area = img[y0:y1, x0:x1]\n",
    "        blue, green, red = np.mean(extract_area, axis=(0, 1))\n",
    "\n",
    "        # TODO　後で消す\n",
    "        blue_list.append(blue)\n",
    "        green_list.append(green)\n",
    "        red_list.append(red)\n",
    "        color_list.append([red / 255, green / 255, blue / 255, 0.75])\n",
    "\n",
    "# TODO 後で消す\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(6, 6), subplot_kw={'projection': '3d'})\n",
    "ax.scatter(blue_list, green_list, red_list, c=color_list)\n",
    "ax.set_xlabel(\"blue\")\n",
    "ax.set_ylabel(\"green\")\n",
    "ax.set_zlabel(\"red\")\n",
    "plt.savefig(\"graph.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e112b-1655-4986-b9e2-4d773ae82d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
